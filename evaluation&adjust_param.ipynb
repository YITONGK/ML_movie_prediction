{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the three data sets\n",
    "train = pd.read_csv(\"A2-Data_files/TMDB_train.csv\")\n",
    "evaluate = pd.read_csv(\"A2-Data_files/TMDB_evaluate.csv\")\n",
    "test = pd.read_csv(\"A2-Data_files/TMDB_test.csv\")\n",
    "unlabelled = pd.read_csv(\"A2-Data_files/TMDB_unlabelled.csv\", low_memory=False)\n",
    "\n",
    "def process_year(year):\n",
    "    if pd.isna(year):\n",
    "        return 'unknown'\n",
    "    if isinstance(year, str) and len(year) == 4 and year.isdigit():\n",
    "        return int(year)\n",
    "    match = re.match(r'(\\d{4})-\\d{2}-\\d{2}', str(year))\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    try:\n",
    "        return pd.to_datetime(year, format='%d/%m/%Y').year\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "unlabelled['release_year'] = unlabelled['release_year'].apply(process_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since some languages may not exist across three data sets, concatenate all the original_language columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "all_languages = pd.concat([train[\"original_language\"], unlabelled[\"original_language\"], evaluate[\"original_language\"], test[\"original_language\"]])\n",
    "# all_languages = all_languages.fillna('unknown')\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_languages)\n",
    "train['original_language'] = label_encoder.transform(train['original_language'])\n",
    "unlabelled['original_language'] = label_encoder.transform(unlabelled['original_language'])\n",
    "evaluate['original_language'] = label_encoder.transform(evaluate['original_language'])\n",
    "test['original_language'] = label_encoder.transform(test['original_language'])\n",
    "\n",
    "# Excluded Features: ['product_of_India', 'product_of_Japan']\n",
    "important_features = ['release_year', 'runtime', 'budget', 'revenue', 'adult', \n",
    "                      'original_language', 'popularity', 'genre_Action', 'genre_Adventure', \n",
    "                      'genre_Animation', 'genre_Comedy', 'genre_Crime', 'genre_Documentary', \n",
    "                      'genre_Drama', 'genre_Family', 'genre_Fantasy', 'genre_History', \n",
    "                      'genre_Horror', 'genre_Music', 'genre_Mystery', 'genre_Romance', \n",
    "                      'genre_Science Fiction', 'genre_TV Movie', 'genre_Thriller', \n",
    "                      'genre_War', 'genre_Western', 'product_of_Canada', 'product_of_France', \n",
    "                      'product_of_Germany', 'product_of_India', 'product_of_Italy', \n",
    "                      'product_of_Japan', 'product_of_Spain', 'product_of_UK', 'product_of_USA', \n",
    "                      'product_of_other_countries', 'vote_count']\n",
    "\n",
    "X_train = train[important_features]\n",
    "y_train = train['rate_category']\n",
    "X_unlabelled = unlabelled[important_features]\n",
    "X_evaluate = evaluate[important_features]\n",
    "y_evaluate = evaluate['rate_category']\n",
    "X_test = test[important_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.697     0.671     0.684      2271\n",
      "           1      0.628     0.705     0.664      2518\n",
      "           2      0.714     0.653     0.682      5593\n",
      "           3      0.746     0.709     0.727      5709\n",
      "           4      0.624     0.758     0.684      2299\n",
      "           5      0.670     0.689     0.680      1610\n",
      "\n",
      "    accuracy                          0.692     20000\n",
      "   macro avg      0.680     0.697     0.687     20000\n",
      "weighted avg      0.696     0.692     0.693     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# record original RF behaviour\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_evaluate)\n",
    "print(classification_report(y_pred, y_evaluate, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 6}\n",
      "Best Cross-validation Score: 0.36\n",
      "Accuracy on Test Set: 0.38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.47      0.37      2184\n",
      "           1       0.40      0.14      0.20      2829\n",
      "           2       0.35      0.53      0.42      5119\n",
      "           3       0.45      0.42      0.44      5420\n",
      "           4       0.43      0.17      0.24      2791\n",
      "           5       0.35      0.39      0.37      1657\n",
      "\n",
      "    accuracy                           0.38     20000\n",
      "   macro avg       0.38      0.35      0.34     20000\n",
      "weighted avg       0.39      0.38      0.36     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use GridSearchCV to do hyperparameter tuning for DT\n",
    "model = DecisionTreeClassifier(random_state=90049)\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "}\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=0, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-validation Score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_evaluate)\n",
    "\n",
    "print(\"Accuracy on Test Set: {:.2f}\".format(accuracy_score(y_evaluate, y_pred)))\n",
    "print(classification_report(y_evaluate, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99289\n",
      "0.6553\n"
     ]
    }
   ],
   "source": [
    "# original accuracy for DT\n",
    "dt_original = DecisionTreeClassifier()\n",
    "dt_original.fit(X_train, y_train)\n",
    "y_pred = dt_original.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(accuracy)\n",
    "y_pred = dt_original.predict(X_evaluate)\n",
    "accuracy = accuracy_score(y_evaluate, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39519\n",
      "0.377\n"
     ]
    }
   ],
   "source": [
    "# accuracy of DT after parameter adjustment\n",
    "dt_improved = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_leaf=1, min_samples_split=6)\n",
    "dt_improved.fit(X_train, y_train)\n",
    "y_pred = dt_improved.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(accuracy)\n",
    "y_pred = dt_improved.predict(X_evaluate)\n",
    "accuracy = accuracy_score(y_evaluate, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 768 candidates, totalling 3840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felikskong/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'max_features': 0.25, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Best Cross-validation Score: 0.40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.58      0.53      2184\n",
      "           1       0.64      0.38      0.48      2829\n",
      "           2       0.53      0.66      0.59      5119\n",
      "           3       0.61      0.67      0.64      5420\n",
      "           4       0.72      0.40      0.51      2791\n",
      "           5       0.51      0.54      0.53      1657\n",
      "\n",
      "    accuracy                           0.57     20000\n",
      "   macro avg       0.58      0.54      0.55     20000\n",
      "weighted avg       0.59      0.57      0.56     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use GridSearchCV to do hyperparameter tuning for RF\n",
    "model = RandomForestClassifier(random_state=90049)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': [0.25, 0.5, 0.75, None],\n",
    "    'max_depth': [15, 20, 25, None],\n",
    "    'min_samples_split': [5, 10, 15, 20],\n",
    "    'min_samples_leaf': [2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=1, n_jobs=8, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-validation Score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_evaluate)\n",
    "\n",
    "print(classification_report(y_evaluate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79665\n",
      "0.6017\n"
     ]
    }
   ],
   "source": [
    "# accuracy of RF after parameter adjustment\n",
    "rf_improved = RandomForestClassifier(random_state=90049,max_depth=20,max_features=0.25,min_samples_leaf=2,min_samples_split=5,n_estimators=500,bootstrap=False)\n",
    "rf_improved.fit(X_train, y_train)\n",
    "y_pred = rf_improved.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(accuracy)\n",
    "y_pred = rf_improved.predict(X_evaluate)\n",
    "accuracy = accuracy_score(y_evaluate, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth=20,max_features='sqrt',min_samples_leaf=2,min_samples_split=5,n_estimators=200\n",
    "0.66677\n",
    "0.5383\n",
    "max_depth=20,max_features=0.25,min_samples_leaf=2,min_samples_split=5,n_estimators=300\n",
    "0.73448\n",
    "0.56965\n",
    "random_state=90049,max_depth=20,max_features=0.25,min_samples_leaf=2,min_samples_split=5,n_estimators=500,bootstrap=False\n",
    "0.79665\n",
    "0.6017\n",
    "all default\n",
    "0.99289\n",
    "0.6913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99289\n",
      "0.6913\n"
     ]
    }
   ],
   "source": [
    "# original behaviour of RF\n",
    "rf_original = RandomForestClassifier(random_state=90049)\n",
    "rf_original.fit(X_train, y_train)\n",
    "y_pred = rf_original.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(accuracy)\n",
    "y_pred = rf_original.predict(X_evaluate)\n",
    "accuracy = accuracy_score(y_evaluate, y_pred)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
