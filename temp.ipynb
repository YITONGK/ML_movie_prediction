{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the three data sets\n",
    "train = pd.read_csv(\"A2-Data_files/TMDB_train.csv\")\n",
    "evaluate = pd.read_csv(\"A2-Data_files/TMDB_evaluate.csv\")\n",
    "test = pd.read_csv(\"A2-Data_files/TMDB_test.csv\")\n",
    "unlabelled = pd.read_csv(\"A2-Data_files/TMDB_unlabelled.csv\", low_memory=False)\n",
    "\n",
    "def process_year(year):\n",
    "    if pd.isna(year):\n",
    "        return 'unknown'\n",
    "    if isinstance(year, str) and len(year) == 4 and year.isdigit():\n",
    "        return int(year)\n",
    "    match = re.match(r'(\\d{4})-\\d{2}-\\d{2}', str(year))\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    try:\n",
    "        return pd.to_datetime(year, format='%d/%m/%Y').year\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "unlabelled['release_year'] = unlabelled['release_year'].apply(process_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since some languages may not exist across three data sets, concatenate all the original_language columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "all_languages = pd.concat([train[\"original_language\"], unlabelled[\"original_language\"], evaluate[\"original_language\"], test[\"original_language\"]])\n",
    "# all_languages = all_languages.fillna('unknown')\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_languages)\n",
    "train['original_language'] = label_encoder.transform(train['original_language'])\n",
    "unlabelled['original_language'] = label_encoder.transform(unlabelled['original_language'])\n",
    "evaluate['original_language'] = label_encoder.transform(evaluate['original_language'])\n",
    "test['original_language'] = label_encoder.transform(test['original_language'])\n",
    "\n",
    "# Excluded Features: ['product_of_India', 'product_of_Japan']\n",
    "important_features = ['release_year', 'runtime', 'budget', 'revenue', 'adult', \n",
    "                      'original_language', 'popularity', 'genre_Action', 'genre_Adventure', \n",
    "                      'genre_Animation', 'genre_Comedy', 'genre_Crime', 'genre_Documentary', \n",
    "                      'genre_Drama', 'genre_Family', 'genre_Fantasy', 'genre_History', \n",
    "                      'genre_Horror', 'genre_Music', 'genre_Mystery', 'genre_Romance', \n",
    "                      'genre_Science Fiction', 'genre_TV Movie', 'genre_Thriller', \n",
    "                      'genre_War', 'genre_Western', 'product_of_Canada', 'product_of_France', \n",
    "                      'product_of_Germany', 'product_of_India', 'product_of_Italy', \n",
    "                      'product_of_Japan', 'product_of_Spain', 'product_of_UK', 'product_of_USA', \n",
    "                      'product_of_other_countries', 'vote_count']\n",
    "\n",
    "X_train = train[important_features]\n",
    "y_train = train['rate_category']\n",
    "X_unlabelled = unlabelled[important_features]\n",
    "X_evaluate = evaluate[important_features]\n",
    "y_evaluate = evaluate['rate_category']\n",
    "X_test = test[important_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_production_companies = scipy.sparse.load_npz('A2-Data_files/TMDB_text_features_bow/train_production_companies_bow.npz')\n",
    "X_train_title = scipy.sparse.load_npz('A2-Data_files/TMDB_text_features_bow/train_title_bow.npz')\n",
    "X_evaluate_production_companies = scipy.sparse.load_npz('A2-Data_files/TMDB_text_features_bow/eval_production_companies_bow.npz')\n",
    "X_evaluate_title = scipy.sparse.load_npz('A2-Data_files/TMDB_text_features_bow/eval_title_bow.npz')\n",
    "X_train_with_text = np.concatenate((X_train.to_numpy(), X_train_production_companies.toarray(), X_train_title.toarray()), axis=1)\n",
    "X_evaluate_with_text = np.concatenate((X_evaluate.to_numpy(), X_evaluate_production_companies.toarray(), X_evaluate_title.toarray()), axis=1)\n",
    "\n",
    "model = RandomForestClassifier(random_state=90049)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['sqrt', 0.25, 0.5],\n",
    "    'max_depth': [20, 25, 30, None],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "# 创建 GridSearchCV 对象\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=0, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# 执行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 最佳参数和最佳得分\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-validation Score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# 使用最佳模型在测试集上进行预测\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_evaluate)\n",
    "\n",
    "# 评估并打印性能\n",
    "print(classification_report(y_evaluate, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
